# SpaCyCleanse

In this project, we worked with a noisy dataset to analyze the impact of preprocessing on the performance of a **Named Entity Recognition (NER)** model. We used several tools to improve data quality, including **spaCy** for model training, **Label Studio** for manual annotation, as well as cleaning techniques based on **Regex**, **XML parsing**, and the removal of unnecessary tags.  Initially, we trained a model on raw, unprocessed data, which resulted in poor performance, with a precision of **15.85%**, recall of **43.33%**, and an F1-score of **23.21%**. To improve these results, we applied a thorough annotation process using **Label Studio**, followed by a retraining of the model with the corrected dataset. After preprocessing, the modelâ€™s performance significantly improved, reaching **92.5%** precision, **84.09%** recall, and an **88.1%** F1-score.  These results highlight the crucial importance of **rigorous preprocessing** and **high-quality annotation** in NLP tasks, demonstrating that proper data cleaning and structuring can lead to a significant increase in model performance.
